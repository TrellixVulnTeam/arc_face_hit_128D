{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "ThongTin = list(os.walk(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/',\n",
       "  ['Ngo Xuan Manh', 'Hoang Thi', 'Luong Tuan Anh', 'Pham Viet Anh'],\n",
       "  []),\n",
       " ('data/Ngo Xuan Manh',\n",
       "  [],\n",
       "  ['8.jpg',\n",
       "   '9.jpg',\n",
       "   '14.jpg',\n",
       "   '15.jpg',\n",
       "   '17.jpg',\n",
       "   '16.jpg',\n",
       "   '12.jpg',\n",
       "   '13.jpg',\n",
       "   '11.jpg',\n",
       "   '10.jpg',\n",
       "   '18.jpg',\n",
       "   '19.jpg',\n",
       "   '4.jpg',\n",
       "   '5.jpg',\n",
       "   '7.jpg',\n",
       "   '6.jpg',\n",
       "   '2.jpg',\n",
       "   '3.jpg',\n",
       "   '1.jpg',\n",
       "   '0.jpg']),\n",
       " ('data/Hoang Thi',\n",
       "  [],\n",
       "  ['8.jpg',\n",
       "   '9.jpg',\n",
       "   '14.jpg',\n",
       "   '15.jpg',\n",
       "   '17.jpg',\n",
       "   '16.jpg',\n",
       "   '12.jpg',\n",
       "   '13.jpg',\n",
       "   '11.jpg',\n",
       "   '10.jpg',\n",
       "   '21.jpg',\n",
       "   '20.jpg',\n",
       "   '22.jpg',\n",
       "   '23.jpg',\n",
       "   '26.jpg',\n",
       "   '18.jpg',\n",
       "   '24.jpg',\n",
       "   '25.jpg',\n",
       "   '19.jpg',\n",
       "   '4.jpg',\n",
       "   '5.jpg',\n",
       "   '7.jpg',\n",
       "   '6.jpg',\n",
       "   '2.jpg',\n",
       "   '3.jpg',\n",
       "   '1.jpg',\n",
       "   '0.jpg']),\n",
       " ('data/Luong Tuan Anh',\n",
       "  [],\n",
       "  ['8.jpg',\n",
       "   '9.jpg',\n",
       "   '14.jpg',\n",
       "   '15.jpg',\n",
       "   '17.jpg',\n",
       "   '16.jpg',\n",
       "   '12.jpg',\n",
       "   '13.jpg',\n",
       "   '11.jpg',\n",
       "   '10.jpg',\n",
       "   '21.jpg',\n",
       "   '20.jpg',\n",
       "   '22.jpg',\n",
       "   '18.jpg',\n",
       "   '19.jpg',\n",
       "   '4.jpg',\n",
       "   '5.jpg',\n",
       "   '7.jpg',\n",
       "   '6.jpg',\n",
       "   '2.jpg',\n",
       "   '3.jpg',\n",
       "   '1.jpg',\n",
       "   '0.jpg']),\n",
       " ('data/Pham Viet Anh',\n",
       "  [],\n",
       "  ['8.jpg',\n",
       "   '9.jpg',\n",
       "   '14.jpg',\n",
       "   '28.jpg',\n",
       "   '29.jpg',\n",
       "   '15.jpg',\n",
       "   '17.jpg',\n",
       "   '16.jpg',\n",
       "   '12.jpg',\n",
       "   '13.jpg',\n",
       "   '39.jpg',\n",
       "   '11.jpg',\n",
       "   '10.jpg',\n",
       "   '38.jpg',\n",
       "   '21.jpg',\n",
       "   '35.jpg',\n",
       "   '34.jpg',\n",
       "   '20.jpg',\n",
       "   '36.jpg',\n",
       "   '22.jpg',\n",
       "   '23.jpg',\n",
       "   '37.jpg',\n",
       "   '33.jpg',\n",
       "   '27.jpg',\n",
       "   '26.jpg',\n",
       "   '32.jpg',\n",
       "   '18.jpg',\n",
       "   '24.jpg',\n",
       "   '30.jpg',\n",
       "   '31.jpg',\n",
       "   '25.jpg',\n",
       "   '19.jpg',\n",
       "   '42.jpg',\n",
       "   '4.jpg',\n",
       "   '5.jpg',\n",
       "   '7.jpg',\n",
       "   '41.jpg',\n",
       "   '40.jpg',\n",
       "   '6.jpg',\n",
       "   '2.jpg',\n",
       "   '3.jpg',\n",
       "   '1.jpg',\n",
       "   '0.jpg'])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThongTin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ngo Xuan Manh', 'Hoang Thi', 'Luong Tuan Anh', 'Pham Viet Anh']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThongTinList = list(os.listdir(path))\n",
    "ThongTinList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ThongTin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ngo Xuan Manh'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThongTin[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/',\n",
       "  ['Ngo Xuan Manh', 'Hoang Thi', 'Luong Tuan Anh', 'Pham Viet Anh'],\n",
       "  ['.DS_Store']),\n",
       " ('data/Ngo Xuan Manh',\n",
       "  [],\n",
       "  ['8.jpg',\n",
       "   '9.jpg',\n",
       "   '14.jpg',\n",
       "   '15.jpg',\n",
       "   '17.jpg',\n",
       "   '16.jpg',\n",
       "   '12.jpg',\n",
       "   '13.jpg',\n",
       "   '11.jpg',\n",
       "   '10.jpg',\n",
       "   '18.jpg',\n",
       "   '19.jpg',\n",
       "   '4.jpg',\n",
       "   '5.jpg',\n",
       "   '7.jpg',\n",
       "   '6.jpg',\n",
       "   '2.jpg',\n",
       "   '3.jpg',\n",
       "   '1.jpg',\n",
       "   '0.jpg']),\n",
       " ('data/Hoang Thi',\n",
       "  [],\n",
       "  ['8.jpg',\n",
       "   '9.jpg',\n",
       "   '14.jpg',\n",
       "   '15.jpg',\n",
       "   '17.jpg',\n",
       "   '16.jpg',\n",
       "   '12.jpg',\n",
       "   '13.jpg',\n",
       "   '11.jpg',\n",
       "   '10.jpg',\n",
       "   '21.jpg',\n",
       "   '20.jpg',\n",
       "   '22.jpg',\n",
       "   '23.jpg',\n",
       "   '26.jpg',\n",
       "   '18.jpg',\n",
       "   '24.jpg',\n",
       "   '25.jpg',\n",
       "   '19.jpg',\n",
       "   '4.jpg',\n",
       "   '5.jpg',\n",
       "   '7.jpg',\n",
       "   '6.jpg',\n",
       "   '2.jpg',\n",
       "   '3.jpg',\n",
       "   '1.jpg',\n",
       "   '0.jpg']),\n",
       " ('data/Luong Tuan Anh',\n",
       "  [],\n",
       "  ['8.jpg',\n",
       "   '9.jpg',\n",
       "   '14.jpg',\n",
       "   '15.jpg',\n",
       "   '17.jpg',\n",
       "   '16.jpg',\n",
       "   '12.jpg',\n",
       "   '13.jpg',\n",
       "   '11.jpg',\n",
       "   '10.jpg',\n",
       "   '21.jpg',\n",
       "   '20.jpg',\n",
       "   '22.jpg',\n",
       "   '18.jpg',\n",
       "   '19.jpg',\n",
       "   '4.jpg',\n",
       "   '5.jpg',\n",
       "   '7.jpg',\n",
       "   '6.jpg',\n",
       "   '2.jpg',\n",
       "   '3.jpg',\n",
       "   '1.jpg',\n",
       "   '0.jpg']),\n",
       " ('data/Pham Viet Anh',\n",
       "  [],\n",
       "  ['8.jpg',\n",
       "   '9.jpg',\n",
       "   '14.jpg',\n",
       "   '28.jpg',\n",
       "   '29.jpg',\n",
       "   '15.jpg',\n",
       "   '17.jpg',\n",
       "   '16.jpg',\n",
       "   '12.jpg',\n",
       "   '13.jpg',\n",
       "   '39.jpg',\n",
       "   '11.jpg',\n",
       "   '10.jpg',\n",
       "   '38.jpg',\n",
       "   '21.jpg',\n",
       "   '35.jpg',\n",
       "   '34.jpg',\n",
       "   '20.jpg',\n",
       "   '36.jpg',\n",
       "   '22.jpg',\n",
       "   '23.jpg',\n",
       "   '37.jpg',\n",
       "   '33.jpg',\n",
       "   '27.jpg',\n",
       "   '26.jpg',\n",
       "   '32.jpg',\n",
       "   '18.jpg',\n",
       "   '24.jpg',\n",
       "   '30.jpg',\n",
       "   '31.jpg',\n",
       "   '25.jpg',\n",
       "   '19.jpg',\n",
       "   '42.jpg',\n",
       "   '4.jpg',\n",
       "   '5.jpg',\n",
       "   '7.jpg',\n",
       "   '41.jpg',\n",
       "   '40.jpg',\n",
       "   '6.jpg',\n",
       "   '2.jpg',\n",
       "   '3.jpg',\n",
       "   '1.jpg',\n",
       "   '0.jpg'])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThongTin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodings = []\n",
    "known_face_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,len(ThongTin),1):\n",
    "    for infor in ThongTin[i][2]:\n",
    "        name = ThongTin[0][1][i-1]\n",
    "        image = infor\n",
    "        full_path = path + \"/\" + name + \"/\"\n",
    "        #print (full_path)\n",
    "        img = face_recognition.load_image_file(full_path + image)\n",
    "        #print(img)\n",
    "        img_encoding = None\n",
    "        try:\n",
    "            img_encoding = face_recognition.face_encodings(img)[0]\n",
    "        except:\n",
    "            continue\n",
    "        #print (img_encoding)\n",
    "        known_face_names.append(name)\n",
    "        known_face_encodings.append(img_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = face_recognition.load_image_file('test.jpg')\n",
    "img_test = cv2.resize(img_test,(240,240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[143, 158, 117],\n",
       "        [146, 161, 120],\n",
       "        [151, 166, 125],\n",
       "        ...,\n",
       "        [133, 147, 112],\n",
       "        [133, 147, 112],\n",
       "        [133, 147, 112]],\n",
       "\n",
       "       [[142, 157, 116],\n",
       "        [147, 162, 121],\n",
       "        [152, 167, 126],\n",
       "        ...,\n",
       "        [134, 148, 113],\n",
       "        [134, 148, 113],\n",
       "        [134, 148, 113]],\n",
       "\n",
       "       [[142, 157, 116],\n",
       "        [147, 162, 121],\n",
       "        [152, 167, 126],\n",
       "        ...,\n",
       "        [133, 147, 112],\n",
       "        [133, 147, 112],\n",
       "        [133, 147, 112]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 30,  45,  68],\n",
       "        [ 35,  50,  73],\n",
       "        [ 34,  50,  73],\n",
       "        ...,\n",
       "        [ 28,  45,  63],\n",
       "        [ 29,  46,  64],\n",
       "        [ 27,  44,  62]],\n",
       "\n",
       "       [[ 23,  38,  61],\n",
       "        [ 29,  44,  67],\n",
       "        [ 28,  44,  67],\n",
       "        ...,\n",
       "        [ 31,  48,  66],\n",
       "        [ 31,  48,  66],\n",
       "        [ 28,  45,  63]],\n",
       "\n",
       "       [[ 17,  32,  55],\n",
       "        [ 22,  37,  60],\n",
       "        [ 22,  38,  61],\n",
       "        ...,\n",
       "        [ 31,  48,  66],\n",
       "        [ 30,  47,  65],\n",
       "        [ 26,  43,  61]]], dtype=uint8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "encod_test = face_recognition.face_encodings(img_test)[0]\n",
    "encod_test = np.asarray(encod_test)\n",
    "encod_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_frame = cv2.resize(img_test, (0, 0), fx=0.5, fy=0.5)\n",
    "rgb_img = small_frame[:, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[145, 160, 119],\n",
       "        [153, 168, 126],\n",
       "        [151, 166, 123],\n",
       "        ...,\n",
       "        [134, 148, 113],\n",
       "        [134, 148, 113],\n",
       "        [134, 148, 113]],\n",
       "\n",
       "       [[144, 160, 119],\n",
       "        [152, 167, 125],\n",
       "        [148, 163, 120],\n",
       "        ...,\n",
       "        [130, 144, 109],\n",
       "        [132, 146, 111],\n",
       "        [133, 147, 112]],\n",
       "\n",
       "       [[145, 162, 120],\n",
       "        [149, 166, 123],\n",
       "        [150, 167, 123],\n",
       "        ...,\n",
       "        [133, 147, 112],\n",
       "        [138, 152, 117],\n",
       "        [142, 156, 121]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 28,  43,  64],\n",
       "        [ 31,  48,  68],\n",
       "        [ 33,  51,  71],\n",
       "        ...,\n",
       "        [  7,  23,  43],\n",
       "        [ 10,  27,  46],\n",
       "        [ 11,  28,  46]],\n",
       "\n",
       "       [[ 33,  48,  71],\n",
       "        [ 33,  49,  72],\n",
       "        [ 29,  46,  68],\n",
       "        ...,\n",
       "        [ 12,  28,  48],\n",
       "        [ 24,  41,  60],\n",
       "        [ 25,  42,  60]],\n",
       "\n",
       "       [[ 23,  38,  61],\n",
       "        [ 24,  40,  63],\n",
       "        [ 21,  38,  61],\n",
       "        ...,\n",
       "        [ 25,  41,  61],\n",
       "        [ 31,  48,  67],\n",
       "        [ 29,  46,  64]]], dtype=uint8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[179, 191, 165],\n",
       "        [177, 184, 160],\n",
       "        [183, 185, 157],\n",
       "        ...,\n",
       "        [108, 110,  84],\n",
       "        [100, 104,  85],\n",
       "        [104, 108,  85]],\n",
       "\n",
       "       [[180, 187, 163],\n",
       "        [179, 186, 161],\n",
       "        [185, 190, 166],\n",
       "        ...,\n",
       "        [104, 102,  75],\n",
       "        [105, 105,  80],\n",
       "        [105, 108,  73]],\n",
       "\n",
       "       [[179, 190, 170],\n",
       "        [175, 186, 165],\n",
       "        [177, 185, 165],\n",
       "        ...,\n",
       "        [114, 105,  80],\n",
       "        [109, 106,  72],\n",
       "        [102, 101,  60]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 71,  52,  31],\n",
       "        [ 66,  50,  29],\n",
       "        [ 58,  46,  26],\n",
       "        ...,\n",
       "        [ 28,  13,   7],\n",
       "        [ 33,  22,  16],\n",
       "        [ 49,  38,  31]],\n",
       "\n",
       "       [[ 63,  44,  25],\n",
       "        [ 54,  40,  25],\n",
       "        [ 54,  43,  36],\n",
       "        ...,\n",
       "        [ 35,  22,  12],\n",
       "        [ 19,  15,   7],\n",
       "        [ 31,  24,  19]],\n",
       "\n",
       "       [[ 56,  37,  14],\n",
       "        [ 52,  42,  26],\n",
       "        [ 47,  41,  33],\n",
       "        ...,\n",
       "        [ 34,  24,   4],\n",
       "        [ 10,  14,   2],\n",
       "        [  6,  14,   5]]], dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(46, 100, 108, 38)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations = face_recognition.face_locations(rgb_img)\n",
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_encodings = face_recognition.face_encodings(rgb_img, face_locations)\n",
    "face_encodings\n",
    "len(face_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58728988]\n",
      "[0.59316465]\n",
      "[0.50711508]\n",
      "[0.4913196]\n",
      "[0.57381135]\n",
      "[0.53626579]\n",
      "[0.62431045]\n",
      "[0.5925443]\n",
      "[0.60857307]\n",
      "[0.6052842]\n",
      "[0.61868942]\n",
      "[0.59619741]\n",
      "[0.62831567]\n",
      "[0.60246494]\n",
      "[0.59625227]\n",
      "[0.60113558]\n",
      "[0.60041689]\n",
      "[0.61568893]\n",
      "[0.62759936]\n",
      "[0.61147172]\n",
      "[0.49207127]\n",
      "[0.49085457]\n",
      "[0.48837763]\n",
      "[0.45751418]\n",
      "[0.47285674]\n",
      "[0.47618836]\n",
      "[0.49181954]\n",
      "[0.49965563]\n",
      "[0.49284426]\n",
      "[0.48761785]\n",
      "[0.52669218]\n",
      "[0.60189187]\n",
      "[0.47498132]\n",
      "[0.49681158]\n",
      "[0.49407138]\n",
      "[0.46575447]\n",
      "[0.50153654]\n",
      "[0.49401317]\n",
      "[0.53756694]\n",
      "[0.47762335]\n",
      "[0.48536541]\n",
      "[0.47871866]\n",
      "[0.49282094]\n",
      "[0.47746725]\n",
      "[0.46637632]\n",
      "[0.47082788]\n",
      "[0.49074389]\n",
      "[0.53282005]\n",
      "[0.55862318]\n",
      "[0.56047813]\n",
      "[0.55966385]\n",
      "[0.52805989]\n",
      "[0.53675661]\n",
      "[0.56427777]\n",
      "[0.54275418]\n",
      "[0.54799103]\n",
      "[0.55568708]\n",
      "[0.49281066]\n",
      "[0.52284465]\n",
      "[0.54925035]\n",
      "[0.50398183]\n",
      "[0.53751268]\n",
      "[0.5263492]\n",
      "[0.51362864]\n",
      "[0.51726911]\n",
      "[0.54527595]\n",
      "[0.51511314]\n",
      "[0.50330778]\n",
      "[0.53263103]\n",
      "[0.34480376]\n",
      "[0.32401525]\n",
      "[0.42722285]\n",
      "[0.5373859]\n",
      "[0.49673715]\n",
      "[0.46609092]\n",
      "[0.43260598]\n",
      "[0.44765303]\n",
      "[0.3778914]\n",
      "[0.36015538]\n",
      "[0.39769969]\n",
      "[0.41223446]\n",
      "[0.37868061]\n",
      "[0.41907233]\n",
      "[0.43821632]\n",
      "[0.45444841]\n",
      "[0.42657804]\n",
      "[0.45936627]\n",
      "[0.38598284]\n",
      "[0.36707896]\n",
      "[0.40582337]\n",
      "[0.50328755]\n",
      "[0.47507777]\n",
      "[0.44875735]\n",
      "[0.47130665]\n",
      "[0.35428247]\n",
      "[0.53095307]\n",
      "[0.34237825]\n",
      "[0.46418499]\n",
      "[0.40684341]\n",
      "[0.35790798]\n",
      "[0.35153714]\n",
      "[0.38113939]\n",
      "[0.37324238]\n",
      "[0.37156391]\n",
      "[0.35337128]\n",
      "[0.35375116]\n",
      "[0.33655173]\n",
      "[0.35869944]\n",
      "[0.36096049]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_encoding = face_encodings[0]\n",
    "max = 1\n",
    "name = \"unknow\"\n",
    "for j in range(0, len(known_face_encodings), 1):\n",
    "    chk = [known_face_encodings[j]]\n",
    "    face_distances = face_recognition.face_distance(chk, face_encoding)\n",
    "    print((face_distances))\n",
    "    if (max > face_distances[0]):\n",
    "        max = face_distances[0]\n",
    "        name = known_face_names[j]\n",
    "max = round(max,3)\n",
    "        #print(max, name)\n",
    "\n",
    "if max > 0.4:\n",
    "    name = \"\"\n",
    "y1, x2, y2, x1 = face_locations[0]\n",
    "y1 = y1 *2\n",
    "x2 = x2 *2\n",
    "y2 = y2 *2\n",
    "x1 = x1 *2\n",
    "cv2.rectangle(img_test, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "        #cv2.rectangle(img, (x1, y1 - 2), (x2, y2), (0, 0, 255), cv2.FILLED )\n",
    "cv2.putText(img_test, str(max)+ name, (x1, y1), cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 0, 0), 1)\n",
    "cv2.imwrite(\"dd.jpg\",img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32 Pham Viet Anh\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(face_encodings),1):\n",
    "    face_encoding = face_encodings[i]\n",
    "\n",
    "    max = 2\n",
    "    name = \"unknow\"\n",
    "    for j in range(0, len(known_face_encodings), 1):\n",
    "        chk = [known_face_encodings[j]]\n",
    "        face_distances = face_recognition.face_distance(chk, face_encoding)\n",
    "\n",
    "        if (max > face_distances[0]):\n",
    "            max = face_distances[0]\n",
    "            name = known_face_names[j]\n",
    "    max = round(max,2)\n",
    "    print(max, name)\n",
    "\n",
    "    if max > 0.3:\n",
    "        name = \"\"\n",
    "    y1, x2, y2, x1 = face_locations[i]\n",
    "    y1 = y1 *2\n",
    "    x2 = x2 *2\n",
    "    y2 = y2 *2\n",
    "    x1 = x1 *2\n",
    "    cv2.rectangle(img_test, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "    #cv2.rectangle(img, (x1, y1 - 2), (x2, y2), (0, 0, 255), cv2.FILLED )\n",
    "    cv2.putText(img_test, str(max)+ name, (x1, y1), cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 0, 0), 1)\n",
    "\n",
    "    cv2.imshow(\"Video\",img_test)\n",
    "    if cv2.waitKey(2)==ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
